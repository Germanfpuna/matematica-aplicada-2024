{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presentacion y generalidades:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modulo 1: Utilizar el dataset Sentiment140. Este dataset también debe de ser pre-procesado de acuerdo al artículo (ver Sección 3.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preprocesado\n",
      "                                         Original_text  sentiment  \\\n",
      "0    i loooooooovvvvvveee my kindle not that the dx...          1   \n",
      "1    reading my kindle love it lee childs is good read          1   \n",
      "2    ok first assesment of the kindle it fucking rocks          1   \n",
      "3    you ll love your kindle i ve had mine for a fe...          1   \n",
      "4    fair enough but i have the kindle and i think ...          1   \n",
      "..                                                 ...        ...   \n",
      "354  after using latex a lot any other typeset math...          1   \n",
      "355  on that note i hate word i hate pages i hate l...          0   \n",
      "356  ahhh back in a real text editing environment i...          1   \n",
      "357  trouble in iran i see hmm iran iran so far awa...          0   \n",
      "358  reading the tweets coming out of iran the whol...          0   \n",
      "\n",
      "                                                  text  \n",
      "0    i love my kindle not that the dx is cool but t...  \n",
      "1    reading my kindle love it lee childs is good read  \n",
      "2    ok first assesment of the kindle it fucking rocks  \n",
      "3    you ll love your kindle i ve had mine for a fe...  \n",
      "4    fair enough but i have the kindle and i think ...  \n",
      "..                                                 ...  \n",
      "354  after using latex a lot any other typeset math...  \n",
      "355  on that note i hate word i hate pages i hate l...  \n",
      "356  ah back in a real text editing environment i l...  \n",
      "357  trouble in iran i see hmm iran iran so far awa...  \n",
      "358  reading the tweets coming out of iran the whol...  \n",
      "\n",
      "[359 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import skfuzzy as fuzz\n",
    "import time\n",
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Eliminar URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Eliminar menciones (@usernames)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    \n",
    "    # Eliminar el símbolo de hashtag (#) pero conservar la palabra\n",
    "    text = re.sub(r'#', '', text)\n",
    "    \n",
    "    # Reemplazar contracciones comunes\n",
    "    contractions = {\n",
    "        \"can't\": \"cannot\", \"cant\": \"cannot\",\n",
    "        \"won't\": \"will not\", \"wont\": \"will not\",\n",
    "        \"I'm\": \"I am\", \"Im\": \"I am\",\n",
    "        \"it's\": \"it is\", \"its\": \"it is\",\n",
    "        \"don't\": \"do not\", \"dont\": \"do not\",\n",
    "        \"you're\": \"you are\", \"youre\": \"you are\",\n",
    "        \"he's\": \"he is\", \"hes\": \"he is\",\n",
    "        \"she's\": \"she is\", \"shes\": \"she is\",\n",
    "        \"they're\": \"they are\", \"theyre\": \"they are\",\n",
    "        \"that's\": \"that is\", \"thats\": \"that is\",\n",
    "        \"what's\": \"what is\", \"whats\": \"what is\",\n",
    "        \"where's\": \"where is\", \"wheres\": \"where is\",\n",
    "        \"who's\": \"who is\", \"whos\": \"who is\",\n",
    "        \"let's\": \"let us\", \"lets\": \"let us\",\n",
    "        \"I've\": \"I have\", \"Ive\": \"I have\",\n",
    "        \"you've\": \"you have\", \"youve\": \"you have\",\n",
    "        \"we've\": \"we have\", \"weve\": \"we have\",\n",
    "        \"they've\": \"they have\", \"theyve\": \"they have\",\n",
    "        \"would've\": \"would have\", \"wouldve\": \"would have\",\n",
    "        \"could've\": \"could have\", \"couldve\": \"could have\",\n",
    "        \"should've\": \"should have\", \"shouldve\": \"should have\",\n",
    "        \"might've\": \"might have\", \"mightve\": \"might have\",\n",
    "        \"must've\": \"must have\", \"mustve\": \"must have\"\n",
    "    }\n",
    "    for contraction, replacement in contractions.items():\n",
    "        text = text.replace(contraction, replacement)\n",
    "    # Eliminar caracteres especiales y numeros \n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Eliminar espacios adicionales\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Reemplazar letras repetidas más de 3 veces por una sola aparición\n",
    "    text = re.sub(r'(.)\\1{2,}', r'\\1', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "# Cargar el dataset Sentiment140\n",
    "def preprosses_dataset(archivo):\n",
    "    # Cargar el dataset\n",
    "    dataset = pd.read_csv(archivo, encoding='latin1', names=['Original_text', 'sentiment'], skiprows=1)\n",
    "    \n",
    "    # Crear una copia de la columna Original_text en la columna text\n",
    "    dataset['text'] = dataset['Original_text']\n",
    "    \n",
    "    # Convertir valores no string a string vacíos y preprocesar la columna de texto\n",
    "    dataset['text'] = dataset['text'].astype(str).apply(preprocess_text)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "data = preprosses_dataset('test_data.csv')\n",
    "\n",
    "print('Dataset preprocesado')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modulo 2: Implementar un módulo que utilice un lexicón de sentimientos de la librería NLTK, y calcule el puntaje positivo y negativo de cada registro en tu dataset siguiendo las instrucciones de la Sección 3.2 del artículo. Al utilizar un analizador de sentimientos de NLTK, solo usar los valores positivos y negativos que retorne. Estos puntajes se deben incluir al dataset como dos columnas nuevas: puntaje positivo y puntaje negativo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset con puntajes de sentimiento:\n",
      "                                         Original_text  sentiment  \\\n",
      "0    i loooooooovvvvvveee my kindle not that the dx...          1   \n",
      "1    reading my kindle love it lee childs is good read          1   \n",
      "2    ok first assesment of the kindle it fucking rocks          1   \n",
      "3    you ll love your kindle i ve had mine for a fe...          1   \n",
      "4    fair enough but i have the kindle and i think ...          1   \n",
      "..                                                 ...        ...   \n",
      "354  after using latex a lot any other typeset math...          1   \n",
      "355  on that note i hate word i hate pages i hate l...          0   \n",
      "356  ahhh back in a real text editing environment i...          1   \n",
      "357  trouble in iran i see hmm iran iran so far awa...          0   \n",
      "358  reading the tweets coming out of iran the whol...          0   \n",
      "\n",
      "                                                  text  positive_score  \\\n",
      "0    i love my kindle not that the dx is cool but t...           0.446   \n",
      "1    reading my kindle love it lee childs is good read           0.470   \n",
      "2    ok first assesment of the kindle it fucking rocks           0.216   \n",
      "3    you ll love your kindle i ve had mine for a fe...           0.204   \n",
      "4    fair enough but i have the kindle and i think ...           0.456   \n",
      "..                                                 ...             ...   \n",
      "354  after using latex a lot any other typeset math...           0.000   \n",
      "355  on that note i hate word i hate pages i hate l...           0.000   \n",
      "356  ah back in a real text editing environment i l...           0.000   \n",
      "357  trouble in iran i see hmm iran iran so far awa...           0.000   \n",
      "358  reading the tweets coming out of iran the whol...           0.000   \n",
      "\n",
      "     negative_score  \n",
      "0             0.000  \n",
      "1             0.000  \n",
      "2             0.000  \n",
      "3             0.135  \n",
      "4             0.000  \n",
      "..              ...  \n",
      "354           0.000  \n",
      "355           0.520  \n",
      "356           0.000  \n",
      "357           0.213  \n",
      "358           0.353  \n",
      "\n",
      "[359 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\ger13\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Descargar los recursos necesarios de NLTK\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Crear una instancia del analizador de sentimientos\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Función para calcular los puntajes de sentimiento\n",
    "def calculate_sentiment_scores(text):\n",
    "    scores = sia.polarity_scores(text)\n",
    "    return scores['pos'], scores['neg']\n",
    "\n",
    "# Aplicar la función a cada registro del dataset\n",
    "data['positive_score'], data['negative_score'] = zip(*data['text'].apply(calculate_sentiment_scores))\n",
    "\n",
    "print('Dataset con puntajes de sentimiento:')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modulo 3: Fuzzificación de los puntajes de sentimiento. Siguiendo las instrucciones de la Sección 3.3 del artículo, se deben crear conjuntos difusos para los puntajes positivos y negativos. Utilizar la librería `scikit-fuzzy` para este propósito.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset con valores difusos:\n",
      "     positive_score                                     positive_fuzzy  \\\n",
      "0             0.446  {'Low': 0, 'Medium': 0.5768945211191685, 'High...   \n",
      "1             0.470  {'Low': 0, 'Medium': 0.5418427021144595, 'High...   \n",
      "2             0.216  {'Low': 0, 'Medium': 0.9128077865809628, 'High...   \n",
      "3             0.204  {'Low': 0, 'Medium': 0.9303336960833174, 'High...   \n",
      "4             0.456  {'Low': 0, 'Medium': 0.562289596533873, 'High'...   \n",
      "..              ...                                                ...   \n",
      "354           0.000                 {'Low': 0, 'Medium': 0, 'High': 0}   \n",
      "355           0.000                 {'Low': 0, 'Medium': 0, 'High': 0}   \n",
      "356           0.000                 {'Low': 0, 'Medium': 0, 'High': 0}   \n",
      "357           0.000                 {'Low': 0, 'Medium': 0, 'High': 0}   \n",
      "358           0.000                 {'Low': 0, 'Medium': 0, 'High': 0}   \n",
      "\n",
      "     negative_score                                     negative_fuzzy  \n",
      "0             0.000                 {'Low': 0, 'Medium': 0, 'High': 0}  \n",
      "1             0.000                 {'Low': 0, 'Medium': 0, 'High': 0}  \n",
      "2             0.000                 {'Low': 0, 'Medium': 0, 'High': 0}  \n",
      "3             0.135  {'Low': 0.13627331295723683, 'Medium': 0.86372...  \n",
      "4             0.000                 {'Low': 0, 'Medium': 0, 'High': 0}  \n",
      "..              ...                                                ...  \n",
      "354           0.000                 {'Low': 0, 'Medium': 0, 'High': 0}  \n",
      "355           0.520  {'Low': 0, 'Medium': 0.46881807918798246, 'Hig...  \n",
      "356           0.000                 {'Low': 0, 'Medium': 0, 'High': 0}  \n",
      "357           0.213  {'Low': 0, 'Medium': 0.9171892639565514, 'High...  \n",
      "358           0.353  {'Low': 0, 'Medium': 0.7127203197624158, 'High...  \n",
      "\n",
      "[359 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define Membership Function\n",
    "\n",
    "def triangular_membership(x, d, e, f):\n",
    "    \"\"\"\n",
    "    Calculate the triangular membership value for a given x.\n",
    "    \n",
    "    Parameters:\n",
    "    x (float): The input value.\n",
    "    d (float): The lower bound of the triangular function.\n",
    "    e (float): The middle value of the triangular function.\n",
    "    f (float): The upper bound of the triangular function.\n",
    "    \n",
    "    Returns:\n",
    "    float: The membership value.\n",
    "    \"\"\"\n",
    "    if x <= d:\n",
    "        return 0\n",
    "    elif d < x <= e:\n",
    "        return (x - d) / (e - d)\n",
    "    elif e < x < f:\n",
    "        return (f - x) / (f - e)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# Calculate Membership Values\n",
    "\n",
    "# Define the parameters for the fuzzy sets\n",
    "min_val = data[['positive_score', 'negative_score']].min().min()\n",
    "mid_val = data[['positive_score', 'negative_score']].mean().mean()\n",
    "max_val = data[['positive_score', 'negative_score']].max().max()\n",
    "# Define the fuzzy sets for positive, negative, and output variables\n",
    "fuzzy_sets = {\n",
    "    \"Low\": (min_val, min_val, mid_val),\n",
    "    \"Medium\": (min_val, mid_val, max_val),\n",
    "    \"High\": (mid_val, max_val, max_val)\n",
    "}\n",
    "\n",
    "# Function to calculate membership values for a given input\n",
    "def calculate_membership_values(x, fuzzy_sets):\n",
    "    \"\"\"\n",
    "    Calculate the membership values for a given input x using the defined fuzzy sets.\n",
    "    \n",
    "    Parameters:\n",
    "    x (float): The input value.\n",
    "    fuzzy_sets (dict): A dictionary containing the fuzzy sets with their parameters.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary with the membership values for each fuzzy set.\n",
    "    \"\"\"\n",
    "    membership_values = {}\n",
    "    for set_name, (d, e, f) in fuzzy_sets.items():\n",
    "        membership_values[set_name] = triangular_membership(x, d, e, f)\n",
    "    return membership_values\n",
    "\n",
    "\n",
    "    # Apply fuzzification to the positive and negative scores\n",
    "positive_fuzzy = []\n",
    "negative_fuzzy = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    positive_fuzzy.append(calculate_membership_values(row['positive_score'], fuzzy_sets))\n",
    "    negative_fuzzy.append(calculate_membership_values(row['negative_score'], fuzzy_sets))\n",
    "\n",
    "data['positive_fuzzy'] = positive_fuzzy\n",
    "data['negative_fuzzy'] = negative_fuzzy\n",
    "\n",
    "print('Dataset con valores difusos:')\n",
    "print(data[['positive_score', 'positive_fuzzy', 'negative_score', 'negative_fuzzy']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modulo 4: Base de reglas. Utilizar skfuzzy para la creación de la base de reglas siguiendo las secciones 3.3.2 y 3.3.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset con salida difusa:\n",
      "                                                  text  positive_score  \\\n",
      "0    i love my kindle not that the dx is cool but t...           0.446   \n",
      "1    reading my kindle love it lee childs is good read           0.470   \n",
      "2    ok first assesment of the kindle it fucking rocks           0.216   \n",
      "3    you ll love your kindle i ve had mine for a fe...           0.204   \n",
      "4    fair enough but i have the kindle and i think ...           0.456   \n",
      "..                                                 ...             ...   \n",
      "354  after using latex a lot any other typeset math...           0.000   \n",
      "355  on that note i hate word i hate pages i hate l...           0.000   \n",
      "356  ah back in a real text editing environment i l...           0.000   \n",
      "357  trouble in iran i see hmm iran iran so far awa...           0.000   \n",
      "358  reading the tweets coming out of iran the whol...           0.000   \n",
      "\n",
      "     negative_score  fuzzy_output  \n",
      "0             0.000       0.00000  \n",
      "1             0.000       0.00000  \n",
      "2             0.000       0.00000  \n",
      "3             0.135       0.44146  \n",
      "4             0.000       0.00000  \n",
      "..              ...           ...  \n",
      "354           0.000       0.00000  \n",
      "355           0.520       0.00000  \n",
      "356           0.000       0.00000  \n",
      "357           0.213       0.00000  \n",
      "358           0.353       0.00000  \n",
      "\n",
      "[359 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Definir las funciones de membresía para las puntuaciones positivas y negativas\n",
    "def pos_low(x, min_val, mid_val):\n",
    "    return triangular_membership(x, min_val, min_val, mid_val)\n",
    "\n",
    "def pos_med(x, min_val, mid_val, max_val):\n",
    "    return triangular_membership(x, min_val, mid_val, max_val)\n",
    "\n",
    "def pos_high(x, mid_val, max_val):\n",
    "    return triangular_membership(x, mid_val, max_val, max_val)\n",
    "\n",
    "def neg_low(x, min_val, mid_val):\n",
    "    return triangular_membership(x, min_val, min_val, mid_val)\n",
    "\n",
    "def neg_med(x, min_val, mid_val, max_val):\n",
    "    return triangular_membership(x, min_val, mid_val, max_val)\n",
    "\n",
    "def neg_high(x, mid_val, max_val):\n",
    "    return triangular_membership(x, mid_val, max_val, max_val)\n",
    "\n",
    "def op_neg(x):\n",
    "    return triangular_membership(x, min_val, min_val, mid_val)\n",
    "\n",
    "def op_neu(x):\n",
    "    return triangular_membership(x, min_val, mid_val, max_val)\n",
    "\n",
    "def op_pos(x):\n",
    "    return triangular_membership(x, mid_val, max_val, max_val)\n",
    "\n",
    "# Definir las reglas de Mamdani\n",
    "def mamdani_rules(pos_score, neg_score, min_val, mid_val, max_val):\n",
    "    rules = {\n",
    "        'R1': min(pos_low(pos_score, min_val, mid_val), neg_low(neg_score, min_val, mid_val)),\n",
    "        'R2': min(pos_med(pos_score, min_val, mid_val, max_val), neg_low(neg_score, min_val, mid_val)),\n",
    "        'R3': min(pos_high(pos_score, mid_val, max_val), neg_low(neg_score, min_val, mid_val)),\n",
    "        'R4': min(pos_low(pos_score, min_val, mid_val), neg_med(neg_score, min_val, mid_val, max_val)),\n",
    "        'R5': min(pos_med(pos_score, min_val, mid_val, max_val), neg_med(neg_score, min_val, mid_val, max_val)),\n",
    "        'R6': min(pos_high(pos_score, mid_val, max_val), neg_med(neg_score, min_val, mid_val, max_val)),\n",
    "        'R7': min(pos_low(pos_score, min_val, mid_val), neg_high(neg_score, mid_val, max_val)),\n",
    "        'R8': min(pos_med(pos_score, min_val, mid_val, max_val), neg_high(neg_score, mid_val, max_val)),\n",
    "        'R9': min(pos_high(pos_score, mid_val, max_val), neg_high(neg_score, mid_val, max_val)),\n",
    "    }\n",
    "    return rules\n",
    "\n",
    "# Agregación de los resultados de las reglas\n",
    "def aggregate_rules(rules):\n",
    "    w_neg = max(rules['R4'], rules['R7'], rules['R8'])\n",
    "    w_neu = max(rules['R1'], rules['R5'], rules['R9'])\n",
    "    w_pos = max(rules['R2'], rules['R3'], rules['R6'])\n",
    "    return w_neg, w_neu, w_pos\n",
    "\n",
    "# Cálculo de las funciones de membresía de los consecuentes\n",
    "def consequent_membership(w_neg, w_neu, w_pos, x):\n",
    "    op_activation_low = min(w_neg, op_neg(x))\n",
    "    op_activation_med = min(w_neu, op_neu(x))\n",
    "    op_activation_high = min(w_pos, op_pos(x))\n",
    "    return max(op_activation_low, op_activation_med, op_activation_high)\n",
    "\n",
    "\n",
    "# Aplicar las reglas de Mamdani y la agregación a cada registro del dataset\n",
    "def apply_fuzzy_logic(row):\n",
    "    pos_score = row['positive_score']\n",
    "    neg_score = row['negative_score']\n",
    "    \n",
    "    # Obtener las reglas de Mamdani\n",
    "    rules = mamdani_rules(pos_score, neg_score, min_val, mid_val, max_val)\n",
    "    \n",
    "    # Agregar los resultados de las reglas\n",
    "    w_neg, w_neu, w_pos = aggregate_rules(rules)\n",
    "    \n",
    "    # Calcular la membresía del consecuente\n",
    "    output = consequent_membership(w_neg, w_neu, w_pos, pos_score - neg_score)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Medir el tiempo inicial\n",
    "start_time = time.time()\n",
    "\n",
    "# Aplicar la lógica difusa a cada registro\n",
    "data['fuzzy_output'] = data.apply(apply_fuzzy_logic, axis=1)\n",
    "\n",
    "print('Dataset con salida difusa:')\n",
    "print(data[['text', 'positive_score', 'negative_score', 'fuzzy_output']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modulo 5: Implementar la defuzzificación siguiendo las instrucciones de la Sección 3.3.4. Como resultado agregar una tercera columna al dataset que será el puntaje del sentimiento para cada registro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset con valores defuzzificados:\n",
      "                                                  text  positive_score  \\\n",
      "0    i love my kindle not that the dx is cool but t...           0.446   \n",
      "1    reading my kindle love it lee childs is good read           0.470   \n",
      "2    ok first assesment of the kindle it fucking rocks           0.216   \n",
      "3    you ll love your kindle i ve had mine for a fe...           0.204   \n",
      "4    fair enough but i have the kindle and i think ...           0.456   \n",
      "..                                                 ...             ...   \n",
      "354  after using latex a lot any other typeset math...           0.000   \n",
      "355  on that note i hate word i hate pages i hate l...           0.000   \n",
      "356  ah back in a real text editing environment i l...           0.000   \n",
      "357  trouble in iran i see hmm iran iran so far awa...           0.000   \n",
      "358  reading the tweets coming out of iran the whol...           0.000   \n",
      "\n",
      "     negative_score  fuzzy_output  defuzzified_value final_sentiment  \n",
      "0             0.000       0.00000           5.836672         Neutral  \n",
      "1             0.000       0.00000           5.836672         Neutral  \n",
      "2             0.000       0.00000           5.836672         Neutral  \n",
      "3             0.135       0.44146           5.076834         Neutral  \n",
      "4             0.000       0.00000           5.836672         Neutral  \n",
      "..              ...           ...                ...             ...  \n",
      "354           0.000       0.00000           5.000000         Neutral  \n",
      "355           0.520       0.00000           1.670007        Negativo  \n",
      "356           0.000       0.00000           5.000000         Neutral  \n",
      "357           0.213       0.00000           1.670007        Negativo  \n",
      "358           0.353       0.00000           1.670007        Negativo  \n",
      "\n",
      "[359 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "def defuzzify_centroid(row, output_mfs, output_range=(0, 10), num_samples=1000):\n",
    "    z = np.linspace(output_range[0], output_range[1], num_samples)\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for zi in z:\n",
    "        memberships = {\n",
    "            \"Negative\": triangular_membership(zi, output_mfs[\"Negative\"][\"d\"], output_mfs[\"Negative\"][\"e\"], output_mfs[\"Negative\"][\"f\"]) * max(row[\"negative_fuzzy\"][\"Low\"], row[\"negative_fuzzy\"][\"Medium\"], row[\"negative_fuzzy\"][\"High\"]),\n",
    "            \"Neutral\": triangular_membership(zi, output_mfs[\"Neutral\"][\"d\"], output_mfs[\"Neutral\"][\"e\"], output_mfs[\"Neutral\"][\"f\"]) * row[\"positive_fuzzy\"][\"Medium\"],\n",
    "            \"Positive\": triangular_membership(zi, output_mfs[\"Positive\"][\"d\"], output_mfs[\"Positive\"][\"e\"], output_mfs[\"Positive\"][\"f\"]) * max(row[\"positive_fuzzy\"][\"Medium\"], row[\"positive_fuzzy\"][\"High\"]),\n",
    "        }\n",
    "        max_membership = max(memberships.values())\n",
    "        numerator += zi * max_membership\n",
    "        denominator += max_membership\n",
    "    return numerator / denominator if denominator != 0 else 5.0\n",
    "\n",
    "\n",
    "def defuzzify_row(row, output_mfs):\n",
    "    \n",
    "    defuzzified_value = defuzzify_centroid(row, output_mfs)\n",
    "    \n",
    "    return defuzzified_value\n",
    "\n",
    "\n",
    "def process_fuzzified_data(df, output_mfs):\n",
    "    defuzzified_values = []\n",
    "    for _, row in df.iterrows():\n",
    "        defuzzified_value = defuzzify_row(row, output_mfs)\n",
    "        defuzzified_values.append(defuzzified_value)\n",
    "\n",
    "    df[\"defuzzified_value\"] = defuzzified_values\n",
    "    df[\"final_sentiment\"] = df[\"defuzzified_value\"].apply(\n",
    "        lambda x: \"Negativo\" if x <= 3.3 else \"Neutral\" if x <= 6.7 else \"Positivo\"\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "output_mfs = {\n",
    "    \"Negative\": {\"d\": 0, \"e\": 0, \"f\": 5},\n",
    "    \"Neutral\": {\"d\": 0, \"e\": 5, \"f\": 10},\n",
    "    \"Positive\": {\"d\": 5, \"e\": 10, \"f\": 10},\n",
    "}\n",
    "\n",
    "# Procesar los datos difusos\n",
    "data = process_fuzzified_data(data, output_mfs)\n",
    "\n",
    "# Medir el tiempo final\n",
    "end_time = time.time()\n",
    "\n",
    "print('Dataset con valores defuzzificados:')\n",
    "print(data[['text', 'positive_score', 'negative_score', 'fuzzy_output', 'defuzzified_value', 'final_sentiment']])\n",
    "\n",
    "aux_structure = data.apply(lambda row: pd.Series({\n",
    "    'Original_text': row['Original_text'],\n",
    "    'sentiment': row['sentiment'],\n",
    "    'positive_score': row['positive_score'],\n",
    "    'negative_score': row['negative_score'],\n",
    "    'positive_fuzzy_Low': row['positive_fuzzy']['Low'],\n",
    "    'positive_fuzzy_Medium': row['positive_fuzzy']['Medium'],\n",
    "    'positive_fuzzy_High': row['positive_fuzzy']['High'],\n",
    "    'negative_fuzzy_Low': row['negative_fuzzy']['Low'],\n",
    "    'negative_fuzzy_Medium': row['negative_fuzzy']['Medium'],\n",
    "    'negative_fuzzy_High': row['negative_fuzzy']['High'],\n",
    "    'fuzzy_output': row['fuzzy_output'],\n",
    "      'defuzzified_value': row['defuzzified_value'],\n",
    "    'final_sentiment': row['final_sentiment']\n",
    "}), axis=1)\n",
    "\n",
    "# Guardar la estructura auxiliar en un archivo CSV\n",
    "aux_structure.to_csv('salida.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modulo 6 - Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de tweets positivos: 10\n",
      "Total de tweets neutrales: 268\n",
      "Total de tweets negativos: 81\n",
      "Tiempo promedio de ejecución por fila: 0.009765 segundos\n",
      "Tiempo total de ejecución: 3.505528 segundos\n"
     ]
    }
   ],
   "source": [
    "# Imprimir cantidad de tweets por sentimiento\n",
    "total_positive = data[data['final_sentiment'] == 'Positivo'].shape[0]\n",
    "total_neutral = data[data['final_sentiment'] == 'Neutral'].shape[0]\n",
    "total_negative = data[data['final_sentiment'] == 'Negativo'].shape[0]\n",
    "\n",
    "print(f'Total de tweets positivos: {total_positive}')\n",
    "print(f'Total de tweets neutrales: {total_neutral}')\n",
    "print(f'Total de tweets negativos: {total_negative}')\n",
    "\n",
    "# Calcular el tiempo total de ejecución\n",
    "total_execution_time = end_time - start_time\n",
    "\n",
    "# Calcular el tiempo promedio de ejecución por tweet\n",
    "average_execution_time = total_execution_time / len(data)\n",
    "\n",
    "# Imprimir el tiempo promedio de ejecución por tweet y el tiempo total de ejecución\n",
    "print(f'Tiempo promedio de ejecución por fila: {average_execution_time:.6f} segundos')\n",
    "print(f'Tiempo total de ejecución: {total_execution_time:.6f} segundos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gracias por su atencion <3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
